{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from config import API_KEY\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from demo import Runner\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = df[df['is_train'] == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"model_path\": \"/home/user/Desktop/nlp_project/mvit32-2.onnx\", \n",
    "    \"video_path\": \"\",                          \n",
    "    \"frame_interval\": 1,                       \n",
    "    \"mean\": [123.675, 116.28, 103.53],            \n",
    "    \"std\": [58.395, 57.12, 57.375],             \n",
    "}\n",
    "conf = OmegaConf.create(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    \n",
    "    video_name = row[\"video_name\"]\n",
    "    \n",
    "\n",
    "    video_path = os.path.join(\"./data/video_segments\", video_name + \".mp4\")\n",
    "    if not os.path.exists(video_path):\n",
    "        continue\n",
    "    conf.video_path = video_path  \n",
    "    try:\n",
    "        runner = Runner(conf.model_path, conf, mp=False, verbose=True)\n",
    "        \n",
    "        print(f\"\\nProcessing video: {video_name}\")\n",
    "        runner.run()\n",
    "        \n",
    "        predictions = list(runner.prediction_list)\n",
    "        with open(\"model_preds.txt\",\"a\") as f:\n",
    "            f.write(video_name)\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\" \".join(predictions))\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "        del runner\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_preds.txt\", \"r\") as f:\n",
    "    preds = f.read()\n",
    "\n",
    "data = {}\n",
    "preds = preds.split(\"\\n\\n\")\n",
    "for p in preds:\n",
    "    if p != \"\":\n",
    "        p = p.split(\"\\n\")\n",
    "        data[p[0]] = {\"preds\" : p[1].replace(\"--- \", '')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test)):\n",
    "    name = df_test.iloc[i]['video_name']\n",
    "    glosses = df_test.iloc[i]['glosses']\n",
    "    if name in data:\n",
    "        data[name]['real'] = glosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(ref_words, hyp_words):\n",
    "    n = len(ref_words)\n",
    "    m = len(hyp_words)\n",
    "    d = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "    for i in range(n + 1):\n",
    "        d[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        d[0][j] = j\n",
    "        \n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = 0 if ref_words[i - 1] == hyp_words[j - 1] else 1\n",
    "            d[i][j] = min(\n",
    "                d[i - 1][j] + 1,   \n",
    "                d[i][j - 1] + 1,     \n",
    "                d[i - 1][j - 1] + cost  \n",
    "            )\n",
    "    return d[n][m]\n",
    "\n",
    "def wer_custom(reference, hypothesis):\n",
    "    if not isinstance(reference, str):\n",
    "        reference = \"\"\n",
    "    if not isinstance(hypothesis, str):\n",
    "        hypothesis = \"\"\n",
    "    ref_words = reference.strip().split()\n",
    "    hyp_words = hypothesis.strip().split()\n",
    "    if len(ref_words) == 0:\n",
    "        return float('inf')\n",
    "    distance = levenshtein_distance(ref_words, hyp_words)\n",
    "    return distance / len(ref_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_results = {}\n",
    "for key, value in data.items():\n",
    "    if 'real' in value:\n",
    "        ref = value['real']\n",
    "        hyp = value['preds']\n",
    "        wer_value = wer_custom(ref, hyp)\n",
    "        wer_results[key] = wer_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_wer = sum(wer_results.values()) / len(wer_results)\n",
    "print(f\"Average WER over {len(wer_results)} samples: {average_wer:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_data_to_chatgpt(data, prompt):\n",
    "    prompt += data\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test)):\n",
    "    name = df_test.iloc[i]['video_name']\n",
    "    transcript = df_test.iloc[i]['transcript']\n",
    "    if name in data:\n",
    "        data[name]['real_transcript'] = transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in data.items():\n",
    "    if 'real' in value and 'preds' in value and 'transcript' in value:\n",
    "        glosses = value['preds']\n",
    "        prediction = send_data_to_chatgpt(glosses, prompt)\n",
    "        data[key]['pred_trancript'] = prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
